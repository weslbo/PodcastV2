{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, fnmatch\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from pydub import AudioSegment\n",
    "from pydub.playback import play\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "code = \"AI-3016\"\n",
    "learn_module = \"all\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineAudio(templocation, savelocation):\n",
    "    input_files = sorted(fnmatch.filter(os.listdir(templocation), '*.mp3'))\n",
    "    final_files = []\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        input_files[i] = os.path.join(templocation, input_files[i])\n",
    "\n",
    "    for i in range(len(input_files)):\n",
    "        if i == 0:\n",
    "            final_files.append(\"media/start.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "        elif i == len(input_files) - 1:\n",
    "            final_files.append(\"media/break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "            final_files.append(\"media/finish.mp3\")\n",
    "        else:\n",
    "            final_files.append(\"media/break.mp3\")\n",
    "            final_files.append(input_files[i])\n",
    "\n",
    "    print(\"- Combining audio files \" + str(final_files))\n",
    "    \n",
    "    # Initialize an empty AudioSegment\n",
    "    combined_audio = AudioSegment.silent(duration=0)\n",
    "\n",
    "    # Iterate through input files and append them to the combined_audio\n",
    "    for input_file in final_files:\n",
    "        audio_segment = AudioSegment.from_file(input_file, format=\"mp3\")\n",
    "        combined_audio += audio_segment\n",
    "\n",
    "    # Export the combined audio to the output file\n",
    "    combined_audio.export(savelocation, format=\"mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/1.Introduction to Azure AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/1.Introduction to Azure AI Studio/2-what-is-ai-studio.mp3', 'media/break.mp3', 'output/AI-3016/1.Introduction to Azure AI Studio/3-azure-ai-resources.mp3', 'media/break.mp3', 'output/AI-3016/1.Introduction to Azure AI Studio/4-when-to-use-ai-studio.mp3', 'media/finish.mp3']\n",
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/2.Explore and deploy models from the model catalog in Azure AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/2.Explore and deploy models from the model catalog in Azure AI Studio/2-select-model.mp3', 'media/break.mp3', 'output/AI-3016/2.Explore and deploy models from the model catalog in Azure AI Studio/3-deploy-model.mp3', 'media/break.mp3', 'output/AI-3016/2.Explore and deploy models from the model catalog in Azure AI Studio/4-improve-model.mp3', 'media/finish.mp3']\n",
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/3.Get started with prompt flow to develop language model apps in the Azure AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/3.Get started with prompt flow to develop language model apps in the Azure AI Studio/2-understand-lifecycle.mp3', 'media/break.mp3', 'output/AI-3016/3.Get started with prompt flow to develop language model apps in the Azure AI Studio/3-understand-flows.mp3', 'media/break.mp3', 'output/AI-3016/3.Get started with prompt flow to develop language model apps in the Azure AI Studio/4-connections-runtimes.mp3', 'media/break.mp3', 'output/AI-3016/3.Get started with prompt flow to develop language model apps in the Azure AI Studio/5-variants-monitor.mp3', 'media/finish.mp3']\n",
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/4.Build a RAG-based copilot solution with your own data using Azure AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/4.Build a RAG-based copilot solution with your own data using Azure AI Studio/2-ground-language-model.mp3', 'media/break.mp3', 'output/AI-3016/4.Build a RAG-based copilot solution with your own data using Azure AI Studio/3-search-data.mp3', 'media/break.mp3', 'output/AI-3016/4.Build a RAG-based copilot solution with your own data using Azure AI Studio/4-build-copilot.mp3', 'media/finish.mp3']\n",
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/5.Integrate a fine-tuned language model with your copilot in the Azure AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/5.Integrate a fine-tuned language model with your copilot in the Azure AI Studio/2-understand-finetune.mp3', 'media/break.mp3', 'output/AI-3016/5.Integrate a fine-tuned language model with your copilot in the Azure AI Studio/3-prepare-data.mp3', 'media/break.mp3', 'output/AI-3016/5.Integrate a fine-tuned language model with your copilot in the Azure AI Studio/4-finetune-model.mp3', 'media/finish.mp3']\n",
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/6.Evaluate the performance of your custom copilot in the Azure AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/6.Evaluate the performance of your custom copilot in the Azure AI Studio/2-assess-models.mp3', 'media/break.mp3', 'output/AI-3016/6.Evaluate the performance of your custom copilot in the Azure AI Studio/3-manual-evaluations.mp3', 'media/break.mp3', 'output/AI-3016/6.Evaluate the performance of your custom copilot in the Azure AI Studio/4-evaluation-flows.mp3', 'media/finish.mp3']\n",
      "- Combining audio files ['media/start.mp3', 'output/AI-3016/7.Responsible generative AI in AI Studio/1-introduction.mp3', 'media/break.mp3', 'output/AI-3016/7.Responsible generative AI in AI Studio/2-plan-responsible-ai.mp3', 'media/break.mp3', 'output/AI-3016/7.Responsible generative AI in AI Studio/3-identify-harms.mp3', 'media/break.mp3', 'output/AI-3016/7.Responsible generative AI in AI Studio/4-measure-harms.mp3', 'media/break.mp3', 'output/AI-3016/7.Responsible generative AI in AI Studio/5-mitigate-harms.mp3', 'media/break.mp3', 'output/AI-3016/7.Responsible generative AI in AI Studio/6-operate-responsibly.mp3', 'media/finish.mp3']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "with open(\"./output/LearningPaths.json\", \"r\") as file:\n",
    "    learning_paths = json.load(file)\n",
    "    \n",
    "for lp in learning_paths:\n",
    "    modules = [module for module in lp[\"learning_modules\"] if module[\"learning_module\"] == learn_module or learn_module == \"all\"]\n",
    "\n",
    "    iModule = 1\n",
    "    for module in modules:\n",
    "        outputFolder_module = f\"output/{code}/{iModule}.{module['learning_module']}\"\n",
    "            \n",
    "        outputFile_module_mp3 = f\"output/{code}/{iModule}.{module['learning_module']}.mp3\"\n",
    "            \n",
    "        combineAudio(outputFolder_module , outputFile_module_mp3)\n",
    "        iModule += 1\n",
    "            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
